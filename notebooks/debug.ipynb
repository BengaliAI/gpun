{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "# imports\n",
    "#---------------------------\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "#---------------------------\n",
    "# helpers\n",
    "#---------------------------\n",
    "punctuations           =    ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', \n",
    "                            '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`',\n",
    "                            '{', '|', '}', '~', '।', '॥','“','”'] \n",
    "def reset(df):\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True) \n",
    "    return df\n",
    "\n",
    "def get_words(text):\n",
    "    if text.strip():\n",
    "        for punct in punctuations+[\"\\n\"]:\n",
    "            text=text.replace(punct,\" \")\n",
    "        words=[word for word in text.split(\" \") if word.strip()]\n",
    "        return Counter(words)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def cvtCounter(counter):\n",
    "    df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "    df = df.rename(columns={'index':'word', 0:'count'})\n",
    "    return df\n",
    "\n",
    "def split_dataframe(df, chunk_size = 1000): \n",
    "    chunks =[]\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n",
    "def process_csv(csv,didx,words_dir):\n",
    "    df=pd.read_csv(csv)\n",
    "    df[\"words\"]=df.text.progress_apply(lambda x:get_words(x))\n",
    "    df=reset(df)\n",
    "    chunks=split_dataframe(df)\n",
    "    for cidx,df in enumerate(chunks):\n",
    "        data=Counter()\n",
    "        for idx in tqdm(range(len(df))):\n",
    "            data+=df.iloc[idx,-1]\n",
    "        data=cvtCounter(data)\n",
    "        _csv=os.path.join(words_dir,f\"{didx}_{cidx}.csv\")\n",
    "        data.to_csv(_csv,index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in [\"bn\",\"hi\",\"ml\",\"gu\",\"ta\",\"pa\",\"or\"]:\n",
    "    data_dir=f\"/backup/Oscar/data/{lang}\"\n",
    "    words_dir=f\"/backup/Oscar/words/{lang}/\"\n",
    "    if not os.path.exists(words_dir):\n",
    "        os.mkdir(words_dir)\n",
    "        \n",
    "    csvs=[csv for csv in glob(os.path.join(data_dir,\"*.csv\"))]\n",
    "    for didx,csv in enumerate(csvs):\n",
    "        print(lang,didx)\n",
    "        process_csv(csv,didx,words_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "# imports\n",
    "#---------------------------\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "#---------------------------\n",
    "# csv\n",
    "#---------------------------\n",
    "def reset(df):\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True) \n",
    "    return df\n",
    "\n",
    "def de_emojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                             u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                             u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                             u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                            \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def clean(text):\n",
    "    text=str(text)\n",
    "    text = re.sub(\"[a-zA-Z0-9]+\", \"\",text)\n",
    "    if len(text)==0:\n",
    "        return None\n",
    "    else:\n",
    "        text=de_emojify(text)\n",
    "        if len(text)>0:\n",
    "            return text\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "lang=\"bn\"\n",
    "data_dir=f\"/backup/Oscar/words/{lang}/\"\n",
    "csvs=[csv for csv in glob(os.path.join(data_dir,\"*.csv\"))]\n",
    "dfs=[pd.read_csv(csv) for csv in tqdm(csvs)]\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "df=reset(df)\n",
    "df[\"word\"]=df[\"word\"].progress_apply(lambda x:clean(x))\n",
    "df=reset(df)\n",
    "# group\n",
    "df_new = df.groupby(df['word']).aggregate({\"count\":\"sum\"})\n",
    "df_new = df_new.sort_values(by='count', ascending=False)\n",
    "# new\n",
    "df=pd.DataFrame({})\n",
    "df[\"word\"]=df_new.index.tolist()\n",
    "df[\"count\"]=df_new[\"count\"].tolist()\n",
    "df[\"count\"]=df[\"count\"].progress_apply(lambda x:int(x))\n",
    "df.to_csv(os.path.join(\"/backup/Oscar/words/\",f\"{lang}.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83cb0fe33a0a67f9f877ffb776c4b7cce63e124f7ba47fe6878fb868bcc96314"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bangla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
